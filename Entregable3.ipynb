{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Módulo 2 Análisis y Reporte sobre el desempeño del modelo. (Portafolio Análisis)\n",
    "\n",
    "Diego Elián Rodríguez Cantú A00829925\n",
    "\n",
    "## Dataset Utilizado\n",
    "\n",
    "**Nombre del Dataset:** SMS Spam Collection Dataset\n",
    "\n",
    "**Enlace al Dataset:** [SMS Spam Collection Dataset](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)\n",
    "\n",
    "**Descripción de los Datos:**\n",
    "\n",
    "- Cantidad de Registros/Muestras: El dataset contiene un total de 5,572 mensajes de texto etiquetados como spam o no spam (\"ham\").\n",
    "\n",
    "- Número de Características: Las características se derivan de la representación de texto en forma de vectores de términos (TF-IDF), por lo que el número de características depende de la dimensionalidad del espacio de términos. En este caso, se han utilizado un máximo de 10,000 términos, lo que significa que cada mensaje se representa mediante un vector de características de longitud 10,000.\n",
    "\n",
    "- Número de Clases de Salida: El problema es de clasificación binaria, por lo que hay dos clases de salida: \"spam\" y \"no spam\" (o \"ham\").\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\elian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\elian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\elian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "# from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "mssgdata = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "X, y = mssgdata.v2, mssgdata.v1\n",
    "\n",
    "documents = []\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "stemmer = WordNetLemmatizer()\n",
    "for sen in range(0, len(X)):\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    document = document.lower()\n",
    "    document = document.split()\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)\n",
    "    \n",
    "vectorizer = CountVectorizer(max_features=10000, min_df=1, max_df=0.6, ngram_range=(1,2), stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separación y evaluación del modelo con un conjunto de prueba y un conjunto de validación (Train/Test/Validation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_temp, y_temp, test_size=0.5, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento y evaluación del modelo base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo base en el conjunto de prueba: 0.98\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Entrenar el modelo de Random Forest con el conjunto de entrenamiento\n",
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred_test = classifier.predict(X_test)\n",
    "\n",
    "# Calcular el accuracy en el conjunto de prueba\n",
    "accuracy_base = accuracy_score(y_test, y_pred_test)\n",
    "print(f'Precisión del modelo base en el conjunto de prueba: {accuracy_base:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[467   0]\n",
      " [ 12  78]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99       467\n",
      "        spam       1.00      0.87      0.93        90\n",
      "\n",
      "    accuracy                           0.98       557\n",
      "   macro avg       0.99      0.93      0.96       557\n",
      "weighted avg       0.98      0.98      0.98       557\n",
      "\n",
      "0.9784560143626571\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred_test))\n",
    "print(classification_report(y_test,y_pred_test))\n",
    "print(accuracy_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnóstico del sesgo y la varianza."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Sesgo: El sesgo se refiere a la diferencia entre las predicciones del modelo y los valores reales en el conjunto de entrenamiento. Si el sesgo es alto, el modelo subajusta los datos.\n",
    "- Varianza: La varianza se refiere a la sensibilidad del modelo a pequeñas variaciones en los datos de entrenamiento. Si la varianza es alta, el modelo sobreajusta los datos.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para diagnosticar el sesgo y la varianza del modelo, podemos utilizar las métricas del informe de clasificación, especialmente la precisión y el f1-score. \n",
    "\n",
    "- Precisión (Exactitud):\n",
    "  - Para la clase 'ham': 0.97\n",
    "  - Para la clase 'spam': 1.00\n",
    "\n",
    "El modelo tiene una alta precisión tanto para la clase 'ham' como para la clase 'spam'. Esto sugiere que el modelo tiende a hacer predicciones precisas para ambas clases en el conjunto de prueba.\n",
    "\n",
    "- Recall (Recuperación):\n",
    "  - Para la clase 'ham': 1.00\n",
    "  - Para la clase 'spam': 0.87\n",
    "\n",
    "El modelo tiene un recall perfecto (1.00) para la clase 'ham', lo que significa que identifica correctamente todos los casos de 'ham' en el conjunto de prueba. Sin embargo, el recall para la clase 'spam' es de 0.87, lo que indica que el modelo no logra identificar todos los casos de 'spam'.\n",
    "\n",
    "- F1-Score:\n",
    "  - Para la clase 'ham': 0.99\n",
    "  - Para la clase 'spam': 0.93\n",
    "\n",
    "El F1-score es una medida que combina la precisión y el recall. Para ambas clases, el F1-score es alto, lo que sugiere un buen equilibrio entre precisión y recall.\n",
    "\n",
    "Conclusión:\n",
    "\n",
    "- El modelo tiene un sesgo bajo para la clase 'ham' debido a su alta precisión y recall.\n",
    "- El modelo tiene un sesgo moderado para la clase 'spam' debido a su alta precisión pero recall no perfecto.\n",
    "- La varianza del modelo parece ser moderada, ya que las métricas no indican overfitting ni un underfitting significativo.\n",
    "\n",
    "En resumen, el modelo base parece funcionar bastante bien para la clasificación de mensajes 'ham' y 'spam', pero podría mejorarse para la clase 'spam' mejorando el recall. Esto podría lograrse mediante la optimización de hiperparámetros o la incorporación de técnicas de regularización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización del modelo mediante técnicas de regularización."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una técnica común para reducir la varianza y evitar el sobreajuste es ajustar los parámetros del modelo. En el caso de Random Forest, puedes ajustar los hiperparámetros como 'n_estimators', 'max_depth', 'min_samples_split', etc., utilizando la validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir la cuadrícula de hiperparámetros a explorar\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 500, 1000],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "}\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=0, min_samples_split=2),\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,  # 5-fold cross-validation\n",
    "                           scoring='accuracy',\n",
    "                           verbose= 1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "y_pred_val = best_classifier.predict(X_val)\n",
    "accuracy_optimized = accuracy_score(y_val, y_pred_val)\n",
    "print(f'Precisión del modelo optimizado en el conjunto de validación: {accuracy_optimized:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
