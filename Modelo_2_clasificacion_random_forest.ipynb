{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entregable 2 modelo de clasificación usando framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Utilizado\n",
    "\n",
    "**Nombre del Dataset:** SMS Spam Collection Dataset\n",
    "\n",
    "**Enlace al Dataset:** [SMS Spam Collection Dataset](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)\n",
    "\n",
    "**Descripción de los Datos:**\n",
    "\n",
    "- Cantidad de Registros/Muestras: El dataset contiene un total de 5,572 mensajes de texto etiquetados como spam o no spam (\"ham\").\n",
    "\n",
    "- Número de Características: Las características se derivan de la representación de texto en forma de vectores de términos (TF-IDF), por lo que el número de características depende de la dimensionalidad del espacio de términos. En este caso, se han utilizado un máximo de 10,000 términos, lo que significa que cada mensaje se representa mediante un vector de características de longitud 10,000.\n",
    "\n",
    "- Número de Clases de Salida: El problema es de clasificación binaria, por lo que hay dos clases de salida: \"spam\" y \"no spam\" (o \"ham\").\n",
    "\n",
    "## Tipo de Problema\n",
    "\n",
    "Este proyecto aborda un problema de **clasificación**. El objetivo es predecir si un mensaje de texto es spam (\"spam\") o no spam (\"ham\") en función de su contenido y características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\elian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\elian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\elian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos\n",
    "\n",
    "\n",
    "En esta sección, se realiza el preprocesamiento de los mensajes de texto. Cada mensaje se somete a una serie de transformaciones, que incluyen la eliminación de caracteres especiales, eliminación de caracteres individuales, conversión a minúsculas y lematización (reducción de palabras a su forma base). Los mensajes preprocesados se almacenan en la lista documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mssgdata = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "X, y = mssgdata.v2, mssgdata.v1\n",
    "\n",
    "documents = []\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # quita todos los caracteres especiales\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "\n",
    "    # quita todos los caracteres solos\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Quita los caracteres solos del inicio\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Sustituye espacios multiples por unicos\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Quita prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # minusculas\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después se utiliza la técnica de vectorización de texto para convertir los mensajes de texto preprocesados en una representación numérica. El método CountVectorizer se utiliza para crear vectores de características a partir de palabras en los mensajes. Se especifican varios parámetros, como el número máximo de características (términos), el rango de n-gramas y las palabras stopwords (palabras comunes que se eliminan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=10000, min_df=1, max_df=0.6, ngram_range=(1,2), stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de la vectorización, se aplica la transformación TF-IDF (Term Frequency-Inverse Document Frequency) a los datos. Esta transformación pondera la importancia de las palabras en los mensajes. El resultado se almacena nuevamente en la matriz X.\n",
    "Por último, se dividen los datos en conjuntos de entrenamiento y prueba. El 80% de los datos se utiliza para entrenar los modelos de clasificación, y el 20% se reserva para evaluar el rendimiento de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.94      0.96       949\n",
      "        spam       0.71      0.89      0.79       166\n",
      "\n",
      "    accuracy                           0.93      1115\n",
      "   macro avg       0.84      0.91      0.87      1115\n",
      "weighted avg       0.94      0.93      0.93      1115\n",
      "\n",
      "[[889  60]\n",
      " [ 19 147]]\n",
      "0.9291479820627803\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "print(accuracy_score(expected,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métricas de rendimiento del modelo Naive Bayes GaussianNB en el conjunto de prueba**\n",
    "\n",
    " Precisión se refiere a la proporción de predicciones positivas que fueron correctas, recall representa la proporción de ejemplos positivos que fueron correctamente identificados, y la puntuación F1 es una medida que combina precisión y recall. \n",
    " \n",
    " El modelo tiene una alta precisión para la clase \"ham\" (no spam) del 98%, pero una precisión más baja del 71% para la clase \"spam\". El recall para \"ham\" es del 94% y para \"spam\" es del 89%, lo que indica que el modelo tiende a identificar mejor los mensajes \"ham\". El accuracy del modelo es del 92.91%, lo que significa que clasifica correctamente el 92.91% de los mensajes en el conjunto de prueba. \n",
    " \n",
    " La matriz de confusión muestra los detalles de las predicciones, donde 889 mensajes \"ham\" se clasificaron correctamente, 60 se clasificaron erróneamente como \"spam\", 19 mensajes \"spam\" se clasificaron erróneamente como \"ham\" y 147 mensajes \"spam\" se clasificaron correctamente. En general, el modelo tiene un buen rendimiento en la identificación de mensajes \"ham\" pero puede mejorar en la identificación de mensajes \"spam\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un modelo de clasificación utilizando el algoritmo Random Forest Classifier. Se configura con 1,000 árboles (estimadores) en el bosque (n_estimators=1000) y se establece una semilla aleatoria (random_state=0) para garantizar que los resultados sean reproducibles. Luego, se entrena el modelo utilizando los datos de entrenamiento (X_train y y_train), donde X_train contiene los vectores numéricos de características de los mensajes de texto y y_train contiene las etiquetas de clasificación (spam o no spam). A continuación, se realiza una predicción en el conjunto de prueba (X_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[949   0]\n",
      " [ 26 140]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99       949\n",
      "        spam       1.00      0.84      0.92       166\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "0.9766816143497757\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión muestra que el modelo realizó 949 predicciones correctas para la clase \"ham\" y 140 predicciones correctas para la clase \"spam\". No hubo 1 predicción incorrecta para \"ham\" y 26 predicciones incorrectas para \"spam\". Esto indica un alto rendimiento en la identificación de ambas clases, con un recall del 100% para \"ham\" y un recall del 84% para \"spam\". El accuracy del modelo es del 97.66%, lo que significa que clasifica correctamente aproximadamente el 98% de los mensajes en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando estos resultados con el modelo Naive Bayes, el modelo Random Forest muestra un rendimiento generalmente superior. Tiene una precisión más alta para ambas clases (\"ham\" y \"spam\") y un recall más alto para la clase \"ham\". Esto sugiere que el modelo Random Forest es más efectivo en la identificación de mensajes de spam y no spam en comparación con el modelo Naive Bayes en este conjunto de datos específico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones con el Modelo Entrenado\n",
    "\n",
    "Dado a que el modelo de RandomForest tuvo un mejor rendimiento prediciendo el conjunto de prueba, se usará este para las predicciones. Se creó la función **clasificador** en el archivo *spam_rf.py*. A continuación, se presentan algunas predicciones realizadas por el modelo entrenado para datos diferentes a los de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\elian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\elian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\elian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from spam_rf import classificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **Ejemplo 1:**\n",
    "\n",
    "   - Mensaje de Texto: \"Free gift! Click to win now!\"\n",
    "   - Predicción del Modelo de Naive Bayes: \n",
    "   - Predicción del Modelo de Random Forest:\n",
    "   - Valor Real: \"spam\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 1629 features, but RandomForestClassifier is expecting 10000 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m classificador(\u001b[39m\"\u001b[39;49m\u001b[39mFree gift! Click to win now!\u001b[39;49m\u001b[39m\"\u001b[39;49m, classifier)\n",
      "File \u001b[1;32mc:\\Users\\elian\\OneDrive\\Escritorio\\TEC\\7mo_semestre\\A00829925_Portafolio_Implementacion\\spam_rf.py:59\u001b[0m, in \u001b[0;36mclassificador\u001b[1;34m(mensaje, classifier)\u001b[0m\n\u001b[0;32m     56\u001b[0m mensajetransformado \u001b[39m=\u001b[39m X[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m     57\u001b[0m X \u001b[39m=\u001b[39m X[:(\u001b[39mlen\u001b[39m(X)\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)]\n\u001b[1;32m---> 59\u001b[0m y_pred \u001b[39m=\u001b[39m classifier\u001b[39m.\u001b[39;49mpredict([mensajetransformado])\n\u001b[0;32m     60\u001b[0m \u001b[39mreturn\u001b[39;00m y_pred\n",
      "File \u001b[1;32mc:\\Users\\elian\\anaconda3\\envs\\titanic\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:823\u001b[0m, in \u001b[0;36mForestClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    802\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpredict\u001b[39m(\u001b[39mself\u001b[39m, X):\n\u001b[0;32m    803\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    804\u001b[0m \u001b[39m    Predict class for X.\u001b[39;00m\n\u001b[0;32m    805\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    821\u001b[0m \u001b[39m        The predicted classes.\u001b[39;00m\n\u001b[0;32m    822\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 823\u001b[0m     proba \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict_proba(X)\n\u001b[0;32m    825\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    826\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mtake(np\u001b[39m.\u001b[39margmax(proba, axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\elian\\anaconda3\\envs\\titanic\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:865\u001b[0m, in \u001b[0;36mForestClassifier.predict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    863\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    864\u001b[0m \u001b[39m# Check data\u001b[39;00m\n\u001b[1;32m--> 865\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_X_predict(X)\n\u001b[0;32m    867\u001b[0m \u001b[39m# Assign chunk of trees to jobs\u001b[39;00m\n\u001b[0;32m    868\u001b[0m n_jobs, _, _ \u001b[39m=\u001b[39m _partition_estimators(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_estimators, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_jobs)\n",
      "File \u001b[1;32mc:\\Users\\elian\\anaconda3\\envs\\titanic\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:599\u001b[0m, in \u001b[0;36mBaseForest._validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    597\u001b[0m \u001b[39mValidate X whenever one tries to predict, apply, predict_proba.\"\"\"\u001b[39;00m\n\u001b[0;32m    598\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[1;32m--> 599\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, dtype\u001b[39m=\u001b[39;49mDTYPE, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    600\u001b[0m \u001b[39mif\u001b[39;00m issparse(X) \u001b[39mand\u001b[39;00m (X\u001b[39m.\u001b[39mindices\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc \u001b[39mor\u001b[39;00m X\u001b[39m.\u001b[39mindptr\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mintc):\n\u001b[0;32m    601\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo support for np.int64 index based sparse matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\elian\\anaconda3\\envs\\titanic\\Lib\\site-packages\\sklearn\\base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    622\u001b[0m     out \u001b[39m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m check_params\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mensure_2d\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m--> 625\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_n_features(X, reset\u001b[39m=\u001b[39;49mreset)\n\u001b[0;32m    627\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\elian\\anaconda3\\envs\\titanic\\Lib\\site-packages\\sklearn\\base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m    413\u001b[0m \u001b[39mif\u001b[39;00m n_features \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_:\n\u001b[1;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    415\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX has \u001b[39m\u001b[39m{\u001b[39;00mn_features\u001b[39m}\u001b[39;00m\u001b[39m features, but \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    416\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis expecting \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_features_in_\u001b[39m}\u001b[39;00m\u001b[39m features as input.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    417\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: X has 1629 features, but RandomForestClassifier is expecting 10000 features as input."
     ]
    }
   ],
   "source": [
    "classificador(\"Free gift! Click to win now!\", classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
