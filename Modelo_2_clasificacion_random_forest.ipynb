{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entregable 2 modelo de clasificación usando framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Utilizado\n",
    "\n",
    "**Nombre del Dataset:** SMS Spam Collection Dataset\n",
    "\n",
    "**Enlace al Dataset:** [SMS Spam Collection Dataset](https://www.kaggle.com/datasets/uciml/sms-spam-collection-dataset)\n",
    "\n",
    "**Descripción de los Datos:**\n",
    "\n",
    "- Cantidad de Registros/Muestras: El dataset contiene un total de 5,572 mensajes de texto etiquetados como spam o no spam (\"ham\").\n",
    "\n",
    "- Número de Características: Las características se derivan de la representación de texto en forma de vectores de términos (TF-IDF), por lo que el número de características depende de la dimensionalidad del espacio de términos. En este caso, se han utilizado un máximo de 10,000 términos, lo que significa que cada mensaje se representa mediante un vector de características de longitud 10,000.\n",
    "\n",
    "- Número de Clases de Salida: El problema es de clasificación binaria, por lo que hay dos clases de salida: \"spam\" y \"no spam\" (o \"ham\").\n",
    "\n",
    "## Tipo de Problema\n",
    "\n",
    "Este proyecto aborda un problema de **clasificación**. El objetivo es predecir si un mensaje de texto es spam (\"spam\") o no spam (\"ham\") en función de su contenido y características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\elian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\elian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\elian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from sklearn.datasets import load_files\n",
    "nltk.download('stopwords')\n",
    "nltk.download('omw-1.4')\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesamiento de datos\n",
    "\n",
    "\n",
    "En esta sección, se realiza el preprocesamiento de los mensajes de texto. Cada mensaje se somete a una serie de transformaciones, que incluyen la eliminación de caracteres especiales, eliminación de caracteres individuales, conversión a minúsculas y lematización (reducción de palabras a su forma base). Los mensajes preprocesados se almacenan en la lista documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mssgdata = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "X, y = mssgdata.v2, mssgdata.v1\n",
    "\n",
    "documents = []\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "stemmer = WordNetLemmatizer()\n",
    "\n",
    "for sen in range(0, len(X)):\n",
    "    # quita todos los caracteres especiales\n",
    "    document = re.sub(r'\\W', ' ', str(X[sen]))\n",
    "\n",
    "    # quita todos los caracteres solos\n",
    "    document = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', document)\n",
    "    \n",
    "    # Quita los caracteres solos del inicio\n",
    "    document = re.sub(r'\\^[a-zA-Z]\\s+', ' ', document) \n",
    "    \n",
    "    # Sustituye espacios multiples por unicos\n",
    "    document = re.sub(r'\\s+', ' ', document, flags=re.I)\n",
    "    \n",
    "    # Quita prefixed 'b'\n",
    "    document = re.sub(r'^b\\s+', '', document)\n",
    "    \n",
    "    # minusculas\n",
    "    document = document.lower()\n",
    "    \n",
    "    # Lemmatization\n",
    "    document = document.split()\n",
    "\n",
    "    document = [stemmer.lemmatize(word) for word in document]\n",
    "    document = ' '.join(document)\n",
    "    \n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después se utiliza la técnica de vectorización de texto para convertir los mensajes de texto preprocesados en una representación numérica. El método CountVectorizer se utiliza para crear vectores de características a partir de palabras en los mensajes. Se especifican varios parámetros, como el número máximo de características (términos), el rango de n-gramas y las palabras stopwords (palabras comunes que se eliminan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=10000, min_df=1, max_df=0.6, ngram_range=(1,2), stop_words=stopwords.words('english'))\n",
    "X = vectorizer.fit_transform(documents).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Después de la vectorización, se aplica la transformación TF-IDF (Term Frequency-Inverse Document Frequency) a los datos. Esta transformación pondera la importancia de las palabras en los mensajes. El resultado se almacena nuevamente en la matriz X.\n",
    "Por último, se dividen los datos en conjuntos de entrenamiento y prueba. El 80% de los datos se utiliza para entrenar los modelos de clasificación, y el 20% se reserva para evaluar el rendimiento de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfconverter = TfidfTransformer()\n",
    "X = tfidfconverter.fit_transform(X).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 1: Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      0.94      0.96       949\n",
      "        spam       0.71      0.89      0.79       166\n",
      "\n",
      "    accuracy                           0.93      1115\n",
      "   macro avg       0.84      0.91      0.87      1115\n",
      "weighted avg       0.94      0.93      0.93      1115\n",
      "\n",
      "[[889  60]\n",
      " [ 19 147]]\n",
      "0.9291479820627803\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))\n",
    "print(accuracy_score(expected,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Métricas de rendimiento del modelo Naive Bayes GaussianNB en el conjunto de prueba**\n",
    "\n",
    " Precisión se refiere a la proporción de predicciones positivas que fueron correctas, recall representa la proporción de ejemplos positivos que fueron correctamente identificados, y la puntuación F1 es una medida que combina precisión y recall. \n",
    " \n",
    " El modelo tiene una alta precisión para la clase \"ham\" (no spam) del 98%, pero una precisión más baja del 71% para la clase \"spam\". El recall para \"ham\" es del 94% y para \"spam\" es del 89%, lo que indica que el modelo tiende a identificar mejor los mensajes \"ham\". El accuracy del modelo es del 92.91%, lo que significa que clasifica correctamente el 92.91% de los mensajes en el conjunto de prueba. \n",
    " \n",
    " La matriz de confusión muestra los detalles de las predicciones, donde 889 mensajes \"ham\" se clasificaron correctamente, 60 se clasificaron erróneamente como \"spam\", 19 mensajes \"spam\" se clasificaron erróneamente como \"ham\" y 147 mensajes \"spam\" se clasificaron correctamente. En general, el modelo tiene un buen rendimiento en la identificación de mensajes \"ham\" pero puede mejorar en la identificación de mensajes \"spam\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 2: Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un modelo de clasificación utilizando el algoritmo Random Forest Classifier. Se configura con 1,000 árboles (estimadores) en el bosque (n_estimators=1000) y se establece una semilla aleatoria (random_state=0) para garantizar que los resultados sean reproducibles. Luego, se entrena el modelo utilizando los datos de entrenamiento (X_train y y_train), donde X_train contiene los vectores numéricos de características de los mensajes de texto y y_train contiene las etiquetas de clasificación (spam o no spam). A continuación, se realiza una predicción en el conjunto de prueba (X_test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[949   0]\n",
      " [ 26 140]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.99       949\n",
      "        spam       1.00      0.84      0.92       166\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.92      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n",
      "0.9766816143497757\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=1000, random_state=0)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matriz de confusión muestra que el modelo realizó 949 predicciones correctas para la clase \"ham\" y 140 predicciones correctas para la clase \"spam\". No hubo 1 predicción incorrecta para \"ham\" y 26 predicciones incorrectas para \"spam\". Esto indica un alto rendimiento en la identificación de ambas clases, con un recall del 100% para \"ham\" y un recall del 84% para \"spam\". El accuracy del modelo es del 97.66%, lo que significa que clasifica correctamente aproximadamente el 98% de los mensajes en el conjunto de prueba."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando estos resultados con el modelo Naive Bayes, el modelo Random Forest muestra un rendimiento generalmente superior. Tiene una precisión más alta para ambas clases (\"ham\" y \"spam\") y un recall más alto para la clase \"ham\". Esto sugiere que el modelo Random Forest es más efectivo en la identificación de mensajes de spam y no spam en comparación con el modelo Naive Bayes en este conjunto de datos específico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones con el Modelo Entrenado\n",
    "\n",
    "Dado a que el modelo de RandomForest tuvo un mejor rendimiento prediciendo el conjunto de prueba, se usará este para las predicciones. Se creó la función **clasificador** en el archivo *spam_rf.py*. A continuación, se presentan algunas predicciones realizadas por el modelo entrenado para datos diferentes a los de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\elian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\elian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\elian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from spam_rf import spam_clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "1. **Ejemplo 1:**\n",
    "\n",
    "   - Mensaje de Texto: \"you are lucky, to claim you prize click here\"\n",
    "   - Predicción del Modelo de Random Forest: spam\n",
    "   - Valor Real: \"spam\"\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_clasificador(\"you are lucky, to claim you prize click here\", classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. **Ejemplo 2:**\n",
    "\n",
    "   - Mensaje de Texto: \"Hello Elias, tell me when you arrive home, please\"\n",
    "   - Predicción del Modelo de Random Forest: ham\n",
    "   - Valor Real: ham"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_clasificador(\"Hello Elias, tell me when you arrive home, please\", classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. **Ejemplo 3:**\n",
    "\n",
    "   - Mensaje de Texto: \"URGENT, we have been trying to contact you. Youve won over 900 thousend dollars, plese send you info to claim the money\"\n",
    "   - Predicción del Modelo de Random Forest: spam\n",
    "   - Valor Real: spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['spam'], dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_clasificador(\"URGENT, we have been trying to contact you. Youve won over 900 thousend dollars, plese send you info to claim the money\", classifier)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titanic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
